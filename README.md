# AiBasedTestFramework
A test framework that helps analyze, create and run tests based on User stories using free, open-source LLMs (powered by gpt4all).

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- ~4GB free disk space (for gpt4all model download on first run)

### Setup

1. **Clone the repository:**
```bash
git clone https://github.com/sridhargoggi-ww/AiBasedTestFramework.git
cd AiBasedTestFramework
```

2. **Create a Python virtual environment:**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies:**
```bash
pip install -r requirements.txt
```

4. **Configure Jira credentials:**
   - Copy `.env.example` to `.env`
   - Edit `.env` and add your Jira credentials:
     ```bash
     JIRA_URL=https://yourcompany.atlassian.net
     JIRA_EMAIL=your-email@company.com
     JIRA_API_TOKEN=<get-from-jira-account-settings>
     JIRA_PROJECT=YOUR_PROJECT_KEY
     ```
   - **âš ï¸ Important:** `.env` is in `.gitignore` and will never be committed
   - Get your API token: Jira â†’ Account Settings â†’ Security â†’ API tokens

5. **Run the test generation agent:**
```bash
python run_agent.py
```

The agent will:
- Fetch requirements from Jira using your credentials
- Use gpt4all (local LLM) to extract acceptance criteria
- Generate manual and automation test cases
- Save artifacts to `test_artifacts/`

### To use with Azure DevOps instead:
Add these environment variables to your `.env` file:
```bash
ADO_ORG_URL=https://dev.azure.com/your-org
ADO_PROJECT=YourProject
ADO_PAT=<your-personal-access-token>
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ ai_agents/              # AI agent implementations
â”‚   â”œâ”€â”€ requirement_analyzer.py   # Uses gpt4all to analyze requirements
â”‚   â”œâ”€â”€ test_generator.py         # Generates test code
â”‚   â””â”€â”€ change_detector.py
â”œâ”€â”€ test_artifacts/         # Generated test artifacts
â”‚   â”œâ”€â”€ automation/        # Automated test scripts (Python/Playwright)
â”‚   â””â”€â”€ manual/           # Manual test documentation (JSON)
â”œâ”€â”€ framework/            # UI testing framework
â”œâ”€â”€ integrations/         # Jira/ADO integrations (optional)
â”œâ”€â”€ metrics/             # Test coverage metrics
â”œâ”€â”€ config.py           # Configuration settings
â””â”€â”€ run_agent.py       # Main entry point
```

## ğŸ¯ Features

âœ… **Free & No API Keys** - Uses gpt4all for local LLM inference  
âœ… **Offline** - Works without internet after initial model download  
âœ… **Automated Test Generation** - Analyzes requirements and generates test code  
âœ… **Regression Tagging** - Tests are tagged as regression for CI/CD  
âœ… **Playwright Integration** - Auto-generates browser automation scripts  

## ï¿½ Security & Credentials

**IMPORTANT:** Never commit credentials to GitHub!

- âœ… Use `.env` file for local development (in `.gitignore`)
- âœ… Set environment variables in CI/CD pipelines
- âœ… Rotate API tokens regularly
- âœ… Use minimal permission API tokens

**Generating Jira API Token:**
1. Go to https://id.atlassian.com/manage/api-tokens
2. Click "Create API token"
3. Copy the token to your `.env` file
4. Never share or commit the token

## ï¿½ğŸ”§ Configuration

Edit `config.py` to customize:
- Test artifact path
- Browser headless mode
- LLM model selection

## ğŸ“ Example Output

The agent generates:
- **Manual Test Cases**: Documented steps and expected results
- **Automation Scripts**: Playwright-based Python test code
- **Test Metadata**: JSON files with test IDs, criteria, and coverage info

## âš™ï¸ Technology Stack

- **LLM**: gpt4all (Mistral 7B)
- **Automation**: Playwright + Python
- **Validation**: Pydantic
- **Framework**: Custom Python-based test framework

## ğŸ“„ Note on venv/

The `venv/` folder is in `.gitignore` and **should not be committed**. When cloning this repo, you only need to:

```bash
python -m venv venv
pip install -r requirements.txt
```

This creates a fresh virtual environment with all required dependencies.
